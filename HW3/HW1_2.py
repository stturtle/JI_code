# -*- coding: utf-8 -*-
"""HW1_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16A3CiTYn4NOAUhtziBfofqqYyDSa0YCs
"""

"""(1)Import the Fashion MNIST dataset..."""

#from __future__ import absolute_import, division, print_function, unicode_literals,os

# TensorFlow and tf.keras
import tensorflow as tf
from tensorflow import keras

# Helper libraries
import numpy as np
import matplotlib.pyplot as plt
import os

fashion_mnist = keras.datasets.fashion_mnist

(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
             'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

"""(2) Explore the data..."""

train_images.shape
len(train_labels)
train_labels
test_images.shape
len(test_labels)
train_images_M = np.expand_dims(train_images, -1)
test_images_M = np.expand_dims(test_images, -1)
print("Num of figures: {:d}".format(train_labels.shape[0]))
print("Size of figure: {:d}x{:d}".format(train_images_M.shape[1], train_images_M.shape[2]))
print("Num of figures: {:d}".format(test_labels.shape[0]))
print("Size of figure: {:d}x{:d}".format(test_images_M.shape[1], test_images_M.shape[2]))

"""Preprocess the data..."""

# Inspect a image in trainging set
plt.figure()
plt.imshow(test_images[2])
plt.colorbar()
plt.grid(False)
plt.show()

# Scale these values by dividing them by 255
train_images = train_images / 255.0
test_images = test_images / 255.0

"""(3) Setup necessary layers..."""

batch_size = 128
nb_classes = 10
nb_epoch = 10

# input image dimensions
img_rows, img_cols = 28, 28
# number of convolutional filters to use
nb_filters = 32
# size of pooling area for max pooling
pool_size = (2,2)
# convolution kernel size
kernel_size = (3,3)

model = tf.keras.models.Sequential()

model.add(tf.keras.layers.BatchNormalization(input_shape=train_images_M.shape[1:]))
model.add(tf.keras.layers.Conv2D(nb_filters,kernel_size, padding='same', activation='relu'))

model.add(tf.keras.layers.BatchNormalization(input_shape=train_images_M.shape[1:]))
model.add(tf.keras.layers.Conv2D(2*nb_filters,kernel_size, padding='same', activation='relu'))
model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))
model.add(tf.keras.layers.Dropout(0.25))

model.add(tf.keras.layers.BatchNormalization(input_shape=train_images_M.shape[1:]))
model.add(tf.keras.layers.Conv2D(3*nb_filters,kernel_size, padding='same', activation='relu'))
model.add(tf.keras.layers.MaxPooling2D(pool_size=pool_size, strides=pool_size))
model.add(tf.keras.layers.Dropout(0.25))

model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(128))
model.add(tf.keras.layers.Activation('elu'))
model.add(tf.keras.layers.Dropout(0.5))
model.add(tf.keras.layers.Dense(nb_classes))
model.add(tf.keras.layers.Activation('softmax'))

model.summary()

"""(4) Compile the model..."""

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

"""(5) Train the model..."""

model.fit(train_images_M, train_labels, epochs=nb_epoch)

"""(6) Evaluate the performance..."""

test_loss, test_acc = model.evaluate(test_images_M, test_labels)# compare how the model performs on the test dataset
print('Test accuracy:', test_acc)

"""Make prediction..."""

predictions = model.predict(test_images_M) # Use the trained model to make predictions about some images

# Graph this to look at the full set of 10 class predictions
def plot_image(i, predictions_array, true_label, img):
  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])
  
  plt.imshow(img, cmap=plt.cm.binary)
  
  predicted_label = np.argmax(predictions_array)
  if predicted_label == true_label:
    color = 'blue'
  else:
    color = 'red'
  
  plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label],
                                100*np.max(predictions_array),
                                class_names[true_label]),
                                color=color)

def plot_value_array(i, predictions_array, true_label):
  predictions_array, true_label = predictions_array[i], true_label[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])
  thisplot = plt.bar(range(10), predictions_array, color="#777777")
  plt.ylim([0, 1])
  predicted_label = np.argmax(predictions_array)
  
  thisplot[predicted_label].set_color('red')
  thisplot[true_label].set_color('blue')
  
# Plot 10 randomly selected testing images, their predicted label, and the true label
# Color correct predictions in blue, incorrect predictions in red
a = np.random.randint(0, len(test_labels), 10)
print('a=',a) 
for i in range(0,10):
  b = a[i]
  plt.figure(figsize=(6, 3))
  plt.subplot(1, 2, 1)
  plot_image(i, predictions, test_labels, test_images)
  plt.subplot(1, 2, 2)
  plot_value_array(i, predictions, test_labels)
plt.show()

"""(7)Apply error analysis..."""

print('x的大小为:', train_images.shape, '\n','y的大小为：', test_images.shape)
train_images_RE = train_images.reshape([60000,784])
test_images_RE = test_images.reshape([10000,784])
print('x的大小为:', train_images_RE.shape, '\n','y的大小为：', test_images_RE.shape)

train_labels_Sandal = (train_labels == 'Sandal')

from sklearn.linear_model import SGDClassifier

sgd_clf = SGDClassifier(max_iter=5, tol=-np.infty, random_state=42)
sgd_clf.fit(train_images_RE, train_labels)

from sklearn.model_selection import cross_val_predict
train_label_pred = cross_val_predict(sgd_clf, train_images_RE, train_labels, cv=3)

from sklearn.metrics import confusion_matrix
conf_mx = confusion_matrix(train_labels, train_label_pred)

def plot_confusion_matrix(matrix):
    """If you prefer color and a colorbar"""
    fig = plt.figure(figsize=(8,8))
    ax = fig.add_subplot(111)
    cax = ax.matshow(matrix)
    fig.colorbar(cax)

plt.matshow(conf_mx, cmap=plt.cm.gray)
plt.show()

row_sums = conf_mx.sum(axis=1, keepdims=True)
norm_conf_mx = conf_mx / row_sums

np.fill_diagonal(norm_conf_mx, 0)
plt.matshow(norm_conf_mx, cmap=plt.cm.gray)
plt.show()